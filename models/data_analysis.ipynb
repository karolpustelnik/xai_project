{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dane USG\n",
    "Dane zawierają klatki z 1515 filmików USG ciązy. Łącznie jest 261765 klatek. Filmiki są róznej rozdzielczosci, niektore 600x800, inne 450x600 jeszcze inne 743x975. \n",
    "Filmiki podzielone są na trzy kategorie:\n",
    "- filmiki głowy (head): 107 - 17522\n",
    "- filmiki brzucha (abdomen): 707 - 118941 klatek\n",
    "- filmiki kości udowej (femur): 701 - 125302 klatek\n",
    "\n",
    "Kazda z klatek jest klasyfikowana jako:\n",
    "- w przypadku filmikow glowy:\n",
    "  - other,\n",
    "  - head non-standard plane (głowa, ale nie w najlepszym ujęciu),\n",
    "  - head standard plane (głowa, w najlepszym ujęciu),\n",
    "- w przypadku filmikow brzucha:\n",
    "  - other,\n",
    "  - abdomen non-standard plane (brzuch, ale nie w najlepszym ujęciu),\n",
    "  - abdomen standard plane (brzuch, w najlepszym ujęciu),\n",
    "- w przypadku filmikow kości udowej:\n",
    "  - other,\n",
    "  - femur non-standard plane (kość udowa, ale nie w najlepszym ujęciu),\n",
    "  - femur standard plane (kość udowa, w najlepszym ujęciu)\n",
    "\n",
    "Filmiki sa roznej dlugosci, najkrotszy ma 14 klatek, najdluzszy ma 551 klatki. Średnio filmiki maja dlugosc około 173 klatek, a najczesciej filmiki maja dlugosc 165 klatek.\n",
    "Klasyfikacji klatek dokonywało 8 lekarzy, przy czym kazdy lekarz mial swoja czesc do klasyfikacji (nie robili tego w formie glosowania).\n",
    "\n",
    "Filmiki dotyczą dzieci kobiet w róznym stadium ciazy. \n",
    "\n",
    "## Rozkład klas\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/outputs/labels_corrected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Class</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1_2</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_1_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_1_5</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261759</th>\n",
       "      <td>708_3_75</td>\n",
       "      <td>5</td>\n",
       "      <td>708_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261760</th>\n",
       "      <td>708_3_76</td>\n",
       "      <td>5</td>\n",
       "      <td>708_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261761</th>\n",
       "      <td>708_3_77</td>\n",
       "      <td>5</td>\n",
       "      <td>708_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261762</th>\n",
       "      <td>708_3_78</td>\n",
       "      <td>5</td>\n",
       "      <td>708_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261763</th>\n",
       "      <td>708_3_79</td>\n",
       "      <td>5</td>\n",
       "      <td>708_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261764 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  Class  video\n",
       "0          1_1_1      1    1_1\n",
       "1          1_1_2      1    1_1\n",
       "2          1_1_3      1    1_1\n",
       "3          1_1_4      1    1_1\n",
       "4          1_1_5      1    1_1\n",
       "...          ...    ...    ...\n",
       "261759  708_3_75      5  708_3\n",
       "261760  708_3_76      5  708_3\n",
       "261761  708_3_77      5  708_3\n",
       "261762  708_3_78      5  708_3\n",
       "261763  708_3_79      5  708_3\n",
       "\n",
       "[261764 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = transforms.Compose([transforms.Resize((450, 600)),\n",
    "                        transforms.Grayscale(num_output_channels=1),\n",
    "                transforms.Pad((0, 0, 0, 150), fill = 0, padding_mode = 'constant'),\n",
    "                transforms.Resize((256, 256)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=0.1354949, std=0.18222201)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_img = torch.rand(3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "rand_img = torch.rand(1, 224, 224)\n",
    "transform = transforms.ToPILImage()\n",
    "rand_img = transform(rand_img)\n",
    "\n",
    "print((t(rand_img)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tensors = list()\n",
    "for i in range(10):\n",
    "    random_tensor = torch.rand(3, 256, 256)\n",
    "    #transform = transforms.ToPILImage()\n",
    "    #pil_img = transform(random_tensor)\n",
    "    list_of_tensors.append(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "l = 10\n",
    "for i in range(l):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor = torch.rand(3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img = transform(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tensors = torch.stack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 256, 256])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = ['1_1']\n",
    "frame = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(10):\n",
    "    labels.append(data.iloc[i][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got numpy.int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2770720/197245378.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got numpy.int64"
     ]
    }
   ],
   "source": [
    "labels= torch.stack(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Class</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, Class, video]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.query('index == 1_1_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.random.rand(3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_mask = np.where(test_img == 1, 0.45, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.71113302, 0.71797107, 0.54212237, ..., 0.0922473 ,\n",
       "         0.7860001 , 0.98604712],\n",
       "        [0.04923913, 0.25677282, 0.33202691, ..., 0.22758941,\n",
       "         0.98223607, 0.41759722],\n",
       "        [0.03140636, 0.52373816, 0.9589957 , ..., 0.22246836,\n",
       "         0.98115397, 0.86686416],\n",
       "        ...,\n",
       "        [0.68038126, 0.85429406, 0.37634871, ..., 0.92638692,\n",
       "         0.13852853, 0.4637915 ],\n",
       "        [0.47847209, 0.89921793, 0.47920737, ..., 0.11882518,\n",
       "         0.49135928, 0.19002587],\n",
       "        [0.7904956 , 0.62030088, 0.46273664, ..., 0.70320497,\n",
       "         0.91098996, 0.22669256]],\n",
       "\n",
       "       [[0.43313803, 0.45002371, 0.82487124, ..., 0.70866591,\n",
       "         0.92748325, 0.64578701],\n",
       "        [0.01863009, 0.68918549, 0.59828515, ..., 0.62514585,\n",
       "         0.73206569, 0.65728843],\n",
       "        [0.9431762 , 0.51371651, 0.0699685 , ..., 0.51040601,\n",
       "         0.80266187, 0.13882744],\n",
       "        ...,\n",
       "        [0.08380276, 0.81649049, 0.05852949, ..., 0.86742445,\n",
       "         0.93995733, 0.40792661],\n",
       "        [0.22098236, 0.03923019, 0.06647757, ..., 0.87366612,\n",
       "         0.94994159, 0.50875219],\n",
       "        [0.99489158, 0.94326246, 0.82674535, ..., 0.20935912,\n",
       "         0.29921287, 0.64006861]],\n",
       "\n",
       "       [[0.30010442, 0.95797543, 0.5821208 , ..., 0.40345507,\n",
       "         0.28611947, 0.35805272],\n",
       "        [0.99983462, 0.64236574, 0.62225638, ..., 0.27722948,\n",
       "         0.8154461 , 0.6764876 ],\n",
       "        [0.73600978, 0.11117741, 0.51965187, ..., 0.01746151,\n",
       "         0.26174187, 0.06755503],\n",
       "        ...,\n",
       "        [0.43451054, 0.37276894, 0.54755449, ..., 0.98539995,\n",
       "         0.42284715, 0.18791355],\n",
       "        [0.91999156, 0.26611629, 0.6288239 , ..., 0.33542957,\n",
       "         0.37188294, 0.46801434],\n",
       "        [0.13007542, 0.16667669, 0.77329248, ..., 0.77900884,\n",
       "         0.85541405, 0.7928989 ]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1154543",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 1154543 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2770720/2785271578.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{vids[0]}_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'{frame}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4113\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4114\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4115\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4116\u001b[0m             \u001b[0;31m# when res is multi-dimensional loc raises, but this is sometimes a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3862\u001b[0m                     \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3864\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3866\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1154543"
     ]
    }
   ],
   "source": [
    "data.query(f'{vids[0]}_' + f'{frame}')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pycocotools\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision\n",
    "import random\n",
    "\n",
    "def load_background(background_path):\n",
    "    im_frame = Image.open(background_path)\n",
    "    np_frame = TF.to_tensor(im_frame)\n",
    "    background = torchvision.transforms.functional.rgb_to_grayscale(np_frame, num_output_channels = 1)\n",
    "    background = background.squeeze(0)\n",
    "    return background\n",
    "\n",
    "def colored_labels_generator(real_data_path, num_of_fake_imgs):\n",
    "    \"\"\"generates fake data of c. elegans\n",
    "    args: real_data_path - path to the real data\n",
    "    num_of_fake_imgs - number of fake images to generate\n",
    "    \n",
    "    outputs: fake imgs saves into fake_data_path\n",
    "    annotations saved as json file 'fake_annotations.json'\n",
    "    \"\"\"\n",
    "    print('Generating fake data...')\n",
    "    \n",
    "    with open('annotations.json') as f: # load annotations\n",
    "        data = json.load(f)\n",
    "    coco = COCO(real_data_path) # load COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coco' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2770720/2783334779.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcoco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'coco' is not defined"
     ]
    }
   ],
   "source": [
    "coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = data['video'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_n = data['video'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = frames_n.index\n",
    "values = frames_n.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['529_3', '418_2', '418_3', '66_3', '58_3', '533_2', '533_3', '605_3',\n",
       "       '605_2', '248_3',\n",
       "       ...\n",
       "       '676_2', '51_3', '52_2', '3_1', '70_3', '641_2', '647_2', '43_3',\n",
       "       '651_3', '93_2'],\n",
       "      dtype='object', length=1515)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_n = pd.DataFrame({'index': indexes, 'frames_n': values}, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_n.to_csv('/data/kpusteln/Fetal-RL/data_preparation/outputs/frames_n.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = []\n",
    "femur = []\n",
    "abdomen = []\n",
    "for row in videos:\n",
    "    row = row.split('_')\n",
    "    if row[1] == '1':\n",
    "        head.append(row[1])\n",
    "    elif row[1] == '3':\n",
    "        femur.append(row[1])\n",
    "    else:\n",
    "        abdomen.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "701\n",
      "707\n"
     ]
    }
   ],
   "source": [
    "print(len(head))\n",
    "print(len(femur))\n",
    "print(len(abdomen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = []\n",
    "femur = []\n",
    "abdomen = []\n",
    "for row in data['video']:\n",
    "    row = row.split('_')\n",
    "    if row[1] == '1':\n",
    "        head.append(row[1])\n",
    "    elif row[1] == '3':\n",
    "        femur.append(row[1])\n",
    "    else:\n",
    "        abdomen.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17522\n",
      "118941\n",
      "125302\n"
     ]
    }
   ],
   "source": [
    "print(len(head))\n",
    "print(len(abdomen))\n",
    "print(len(femur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529_3    551\n",
       "418_2    543\n",
       "418_3    543\n",
       "66_3     516\n",
       "58_3     516\n",
       "        ... \n",
       "641_2     22\n",
       "647_2     20\n",
       "43_3      16\n",
       "651_3     15\n",
       "93_2      14\n",
       "Name: video, Length: 1515, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.78217821782178\n",
      "165.0\n"
     ]
    }
   ],
   "source": [
    "print(frames_n.mean())\n",
    "print(frames_n.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_chart_plotly():\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.io as pio\n",
    "    pio.renderers.default = \"browser\"\n",
    "    fig = go.Figure(data=[go.Pie(labels=['Head', 'Abdomen', 'Femur'], values=[len(head), len(abdomen), len(femur)])])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart_plotly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_chart():\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    labels = 'Head', 'Abdomen', 'Femur'\n",
    "    sizes = [len(head), len(abdomen), len(femur)]\n",
    "    colors = ['gold', 'yellowgreen', 'lightcoral']\n",
    "    explode = (0.1, 0, 0)  # explode 1st slice\n",
    "    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "            autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    108013\n",
       "5     55095\n",
       "6     39643\n",
       "0     35512\n",
       "1     15649\n",
       "4      4952\n",
       "2      2901\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = []\n",
    "femur = []\n",
    "abdomen = []\n",
    "for row in data['video']:\n",
    "    row = row.split('_')\n",
    "    if row == '1_1':\n",
    "        head.append(row[1])\n",
    "    elif row[1] == '3':\n",
    "        femur.append(row[1])\n",
    "    else:\n",
    "        abdomen.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "head1 = data[data['video'] == '1_1']\n",
    "head2 = data[data['video'] == '93_1']\n",
    "\n",
    "abdomen1 = data[data['video'] == '1_2']\n",
    "abdomen2 = data[data['video'] == '633_2']\n",
    "\n",
    "femur1 = data[data['video'] == '1_3']\n",
    "femur2 = data[data['video'] == '705_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "head1.to_csv('/data/kpusteln/head1.csv', index = False)\n",
    "head2.to_csv('/data/kpusteln/head2.csv', index = False)\n",
    "\n",
    "abdomen1.to_csv('/data/kpusteln/abdomen1.csv', index = False)\n",
    "abdomen2.to_csv('/data/kpusteln/abdomen2.csv', index = False)\n",
    "\n",
    "femur1.to_csv('/data/kpusteln/femur1.csv', index = False)\n",
    "femur2.to_csv('/data/kpusteln/femur2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['video'] = data['video'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['video'][261484] == '705_3'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
